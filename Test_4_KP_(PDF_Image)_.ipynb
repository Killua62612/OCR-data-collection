{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgEZK20FfAulq+t3FzjFCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Killua62612/OCR-data-collection/blob/main/Test_4_KP_(PDF_Image)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43tpfKq1IxQg"
      },
      "outputs": [],
      "source": [
        "# TensorFlow\n",
        "# !pip install python-doctr[tf]\n",
        "# PyTorch\n",
        "\n",
        "!pip install python-doctr[torch]\n",
        "\n",
        "#Needed for exporting data\n",
        "\n",
        "!pip install tabula-py\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJZgLM_CIzKf"
      },
      "outputs": [],
      "source": [
        "# Colab related installations to install pyproject.toml projects correctly\n",
        "!sudo apt install libcairo2-dev pkg-config\n",
        "!pip3 install pycairo\n",
        "# Install the most up-to-date version from GitHub\n",
        "# TensorFlow\n",
        "# !pip install python-doctr[tf]@git+https://github.com/mindee/doctr.git\n",
        "# PyTorch\n",
        "!pip3 install python-doctr[torch]@git+https://github.com/mindee/doctr.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwYB7mbC-esC"
      },
      "outputs": [],
      "source": [
        "# Pre-requirement python PIP install\n",
        "!sudo apt-get install fonts-freefont-ttf -y\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "# Let's pick the desired backend\n",
        "# os.environ['USE_TF'] = '1'\n",
        "os.environ['USE_TORCH'] = '1'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from doctr.io import DocumentFile\n",
        "from doctr.models import ocr_predictor\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Upload the PDF or image file into Colab\n",
        "# Uncomment the import statement for file upload\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the file to Colab\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "# Check if either PDF or image file is uploaded\n",
        "if 'pdf_file.pdf' in uploaded_files:\n",
        "    file_type = 'pdf'\n",
        "    filename = 'pdf_file.pdf'\n",
        "elif any(fname.endswith(('.jpeg', '.jpg', '.png')) for fname in uploaded_files.keys()):\n",
        "    file_type = 'image'\n",
        "    filenames = [fname for fname in uploaded_files.keys() if fname.endswith(('.jpeg', '.jpg', '.png'))]\n",
        "else:\n",
        "    print(\"Please upload either a PDF or image file.\")\n",
        "    file_type = None\n",
        "\n",
        "if file_type:\n",
        "    # Initialize the OCR predictor model\n",
        "    model = ocr_predictor(pretrained=True)\n",
        "\n",
        "    if file_type == 'pdf':\n",
        "        # Create a DocumentFile instance from the uploaded PDF\n",
        "        doc = DocumentFile.from_pdf(filename)\n",
        "    else:\n",
        "        # Convert image files to a PDF file\n",
        "        pdf_filename = 'converted_images.pdf'\n",
        "        images = [Image.open(io.BytesIO(uploaded_files[img_filename])) for img_filename in filenames]\n",
        "        images[0].save(pdf_filename, save_all=True, append_images=images[1:])\n",
        "\n",
        "        # Create a DocumentFile instance from the converted PDF\n",
        "        doc = DocumentFile.from_pdf(pdf_filename)\n",
        "\n",
        "    # Analyze the document with OCR\n",
        "    result = model(doc)\n",
        "\n",
        "    # Create an empty list to store extracted text from each page\n",
        "    extracted_text_list = []\n",
        "\n",
        "    # Instantiate a pretrained model\n",
        "    predictor = ocr_predictor(pretrained=True)\n",
        "\n",
        "    # Print or use the extracted text as needed\n",
        "    # ... (rest of your code)\n",
        "    result = predictor(doc)\n",
        "\n",
        "    result.show(doc)\n",
        "\n",
        "    synthetic_pages = result.synthesize()\n",
        "    plt.imshow(synthetic_pages[0])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the OCR predictor model\n",
        "model = ocr_predictor(pretrained=True)\n",
        "\n",
        "# Create empty lists to store the extracted numbers and words\n",
        "numbers = []\n",
        "words = []\n",
        "\n",
        "# Analyze the entire document with OCR\n",
        "doc_result = model(doc)\n",
        "\n",
        "# Initialize variables to track the current word and area\n",
        "current_word = \"\"\n",
        "current_area = \"\"\n",
        "\n",
        "# Iterate through the pages, blocks, lines, and words to extract text and areas\n",
        "for page in doc_result.pages:\n",
        "    for block in page.blocks:\n",
        "        for line in block.lines:\n",
        "            for word in line.words:\n",
        "                current_value = word.value\n",
        "                # Check if the word contains any digits (indicating numbers)\n",
        "                if any(char.isdigit() for char in current_value):\n",
        "                    current_area = current_value\n",
        "                else:\n",
        "                    current_word = current_value\n",
        "\n",
        "                # If both word and area are available, append them to the respective lists\n",
        "                if current_word and current_area:\n",
        "                    numbers.append(current_area)\n",
        "                    words.append(current_word)\n",
        "                    current_word = \"\"\n",
        "                    current_area = \"\"\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame({'Words': words, 'Numbers': numbers})\n",
        "\n",
        "# Sort the DataFrame alphabetically by the \"Word\" column\n",
        "df = df.sort_values(by='Words')\n",
        "\n",
        "# Define the output Excel file name\n",
        "excel_filename = 'output.xlsx'\n",
        "\n",
        "# Export the DataFrame to an Excel file\n",
        "df.to_excel(excel_filename, index=False)\n",
        "\n",
        "# Download the Excel file\n",
        "files.download(excel_filename)\n"
      ],
      "metadata": {
        "id": "_NyZp6fdJlTA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}